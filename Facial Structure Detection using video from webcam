import cv2
import mediapipe as mp
import tensorflow as tf

# Load the Keras model
model = tf.keras.models.load_model("D:\Projects\Teachable_Machine_Model\keras_model.h5")

# Initialize MediaPipe face detection
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)

# Initialize the webcam capture
cap = cv2.VideoCapture(0)  # Use 0 for default webcam, change if you have multiple cameras

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()

    # Check if frame capture was successful
    if not ret:
        print("Error: Unable to capture frame from webcam")
        break

    # Convert the frame to RGB format (MediaPipe requires RGB input)
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Perform face mesh detection
    results = face_mesh.process(frame_rgb)

    # Draw dots and lines around the detected faces
    if results.multi_face_landmarks:
        for face_landmarks in results.multi_face_landmarks:
            ih, iw, _ = frame.shape
            for landmark in face_landmarks.landmark:
                x, y = int(landmark.x * iw), int(landmark.y * ih)
                cv2.circle(frame, (x, y), 2, (0, 0, 255), -1)  # Draw dots in red

            # Connect facial landmarks with lines to outline the facial structure
            connections = mp_face_mesh.FACEMESH_TESSELATION
            for connection in connections:
                for i in range(len(connection) - 1):
                    pt1 = (int(face_landmarks.landmark[connection[i]].x * iw), int(face_landmarks.landmark[connection[i]].y * ih))
                    pt2 = (int(face_landmarks.landmark[connection[i + 1]].x * iw), int(face_landmarks.landmark[connection[i + 1]].y * ih))
                    cv2.line(frame, pt1, pt2, (0, 255, 0), 1)  # Draw lines in green

    # Display the frame with detected faces
    cv2.imshow('Face Detection', frame)

    # Break the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the capture
cap.release()
cv2.destroyAllWindows()
